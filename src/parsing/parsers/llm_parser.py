"""
LLMè§£æå™¨

ä½¿ç”¨LLMæœåŠ¡è¿›è¡Œå†…å®¹è§£æçš„ç»Ÿä¸€å®ç°ã€‚
"""

import json
import logging
import os
import time
from typing import Any, Dict, Optional

from src.llm.service_factory import create_llm_service
from src.parsing.base_parser import BaseParser
from src.parsing.prompt_templates import get_prompt_template

logger = logging.getLogger(__name__)

# å®šä¹‰é¡¹ç›®æ ¹ç›®å½•å’Œä¸´æ—¶ç›®å½•å¸¸é‡
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
TEMP_ROOT = os.path.join(PROJECT_ROOT, "temp")


class LLMParser(BaseParser):
    """
    LLMè§£æå™¨

    ä½¿ç”¨ä¸åŒçš„LLMæœåŠ¡è§£æå†…å®¹çš„ç»Ÿä¸€å®ç°ã€‚
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–LLMè§£æå™¨

        Args:
            config: é…ç½®å‚æ•°ï¼ŒåŒ…å«providerä¿¡æ¯
        """
        super().__init__(config)

        self.config = config or {}
        self.provider = self.config.get("provider", "openai")

        try:
            # åˆ›å»ºLLMæœåŠ¡å®ä¾‹
            self.llm_service = create_llm_service(self.provider, self.config)
        except Exception as e:
            raise

        # åˆå§‹åŒ–ç¼“å­˜
        self._cache = {}

        # ç³»ç»Ÿæç¤º
        self.system_prompts = {
            "workflow": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å·¥ä½œæµåˆ†æä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ä»”ç»†åˆ†æè§„åˆ™æ–‡æ¡£ä¸­å®šä¹‰çš„æµç¨‹
2. æ ¹æ®æä¾›çš„æ¨¡æ¿ç»“æ„ï¼Œè¯†åˆ«æµç¨‹ä¸­çš„å„ä¸ªé˜¶æ®µã€æ£€æŸ¥é¡¹å’Œäº¤ä»˜ç‰©
3. ç†è§£é˜¶æ®µä¹‹é—´çš„è½¬æ¢å…³ç³»å’Œæ¡ä»¶
4. å°†åˆ†æç»“æœè½¬æ¢ä¸ºç»“æ„åŒ–çš„JSONæ ¼å¼
5. ç¡®ä¿è¾“å‡ºçš„JSONæ ¼å¼å®Œå…¨ç¬¦åˆæ¨¡æ¿è¦æ±‚çš„ç»“æ„""",
            "roadmap": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è·¯çº¿å›¾ç»“æ„åŒ–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ä»”ç»†åˆ†ææä¾›çš„è·¯çº¿å›¾YAMLå†…å®¹
2. å°†å†…å®¹è½¬æ¢ä¸ºæ ‡å‡†çš„epic-story-taskç»“æ„
3. ç¡®ä¿æ‰€æœ‰å­—æ®µåå’Œå€¼ç¬¦åˆæ ‡å‡†æ ¼å¼
4. ç‰¹åˆ«æ³¨æ„å°†milestoneç»“æ„è½¬æ¢ä¸ºepic-storyç»“æ„
5. ç¡®ä¿priorityå­—æ®µä½¿ç”¨æ ‡å‡†å€¼(low, medium, high, critical)
6. å°†ç»“æœä»¥JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡æœ¬
7. ç¡®ä¿è¾“å‡ºçš„JSONæ ¼å¼å®Œå…¨ç¬¦åˆè¦æ±‚çš„ç»“æ„""",
            "generic": "You are a helpful assistant that parses content accurately.",
        }

    def get_temp_dir(self, sub_dir=None, use_timestamp=True):
        """è·å–é¡¹ç›®ä¸´æ—¶ç›®å½•è·¯å¾„

        Args:
            sub_dir: å¯é€‰çš„å­ç›®å½•å
            use_timestamp: æ˜¯å¦ä½¿ç”¨æ—¶é—´æˆ³åˆ›å»ºå­ç›®å½•ï¼Œé»˜è®¤ä¸ºTrue

        Returns:
            str: ä¸´æ—¶ç›®å½•çš„ç»å¯¹è·¯å¾„
        """
        # è·å–å½“å‰æ—¶é—´æˆ³ä½œä¸ºç›®å½•å
        timestamp = time.strftime("%Y%m%d_%H%M%S")

        # å¦‚æœæä¾›äº†å­ç›®å½•åï¼Œåˆ™åœ¨tempä¸‹åˆ›å»ºç‰¹å®šç±»å‹çš„å­ç›®å½•
        if sub_dir:
            # é¦–å…ˆåˆ›å»ºç±»å‹å­ç›®å½•
            type_dir = os.path.join(TEMP_ROOT, sub_dir)
            os.makedirs(type_dir, exist_ok=True)

            # å¦‚æœéœ€è¦æ—¶é—´æˆ³å­ç›®å½•
            if use_timestamp:
                # åœ¨ç±»å‹å­ç›®å½•ä¸‹åˆ›å»ºæ—¶é—´æˆ³å­ç›®å½•
                timestamped_dir = os.path.join(type_dir, timestamp)
                os.makedirs(timestamped_dir, exist_ok=True)
                return timestamped_dir

            return type_dir

        # å¦‚æœæ²¡æœ‰æä¾›å­ç›®å½•åï¼Œåˆ™ç›´æ¥è¿”å›åŸºç¡€tempç›®å½•
        os.makedirs(TEMP_ROOT, exist_ok=True)
        return TEMP_ROOT

    async def parse_text(self, content: str, content_type: Optional[str] = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨LLMæœåŠ¡è§£ææ–‡æœ¬å†…å®¹

        Args:
            content: å¾…è§£æçš„æ–‡æœ¬å†…å®¹
            content_type: å†…å®¹ç±»å‹ï¼Œå¦‚'rule'ã€'document'ç­‰

        Returns:
            è§£æç»“æœ
        """
        # å¦‚æœæœªæŒ‡å®šå†…å®¹ç±»å‹ï¼Œé»˜è®¤ä¸ºé€šç”¨ç±»å‹
        content_type = content_type or "generic"

        # è·å–å¯¹åº”çš„æç¤ºæ¨¡æ¿
        prompt_template = get_prompt_template(content_type)

        # è·å–ç³»ç»Ÿæç¤º
        system_prompt = self.system_prompts.get(content_type, "You are a helpful assistant that parses content accurately.")

        # æ ¼å¼åŒ–æç¤º
        prompt = prompt_template.format(content=content)

        # å‡†å¤‡æ¶ˆæ¯
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt},
        ]

        logger.info(f"ä½¿ç”¨ {content_type} æç¤ºæ¨¡æ¿è¿›è¡Œè§£æ")

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶æ¥ä¿å­˜è¯·æ±‚å†…å®¹
        # è·å–å½“å‰æ—¶é—´æˆ³
        timestamp = int(time.time())

        # åˆ›å»ºæ—¶é—´æˆ³å­ç›®å½•
        timestamp_dir = self.get_temp_dir("llm_logs")

        # ä¿å­˜è¯·æ±‚å†…å®¹
        request_file = os.path.join(timestamp_dir, f"request_{timestamp}.txt")
        with open(request_file, "w", encoding="utf-8") as f:
            # ä¿å­˜è¯¦ç»†è¯·æ±‚å†…å®¹ï¼ŒåŒ…æ‹¬ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æç¤º
            f.write(f"å†…å®¹ç±»å‹: {content_type}\n\n")
            f.write(f"ç³»ç»Ÿæç¤º:\n{system_prompt}\n\n")
            f.write(f"ç”¨æˆ·æç¤º:\n{prompt}\n\n")
            f.write(f"åŸå§‹å†…å®¹:\n{content}")
        logger.info(f"ğŸ“ å·²ä¿å­˜LLMè¯·æ±‚å†…å®¹åˆ°: {request_file}")

        # ç”¨äºå­˜å‚¨åŸå§‹å“åº”æ–‡æœ¬ï¼Œå³ä½¿å‘ç”Ÿå¼‚å¸¸ä¹Ÿèƒ½ä¿å­˜
        result_text = ""

        # è°ƒç”¨LLMæœåŠ¡
        try:
            logger.info("ğŸš€ å¼€å§‹è°ƒç”¨LLMæœåŠ¡...")
            response = await self.llm_service.chat_completion(messages)
            logger.info("âœ… LLMæœåŠ¡è°ƒç”¨æˆåŠŸ")

            # æ ¹æ®ä¸åŒçš„LLMæœåŠ¡æä¾›è€…å¤„ç†å“åº”
            if hasattr(response, "choices") and hasattr(response.choices[0], "message"):
                # OpenAI APIçš„åŸç”Ÿå¯¹è±¡æ ¼å¼
                result_text = response.choices[0].message.content
            else:
                # å­—å…¸æ ¼å¼çš„å“åº”
                result_text = response["choices"][0]["message"]["content"]

            logger.info("ğŸ“¥ è·å–åˆ°LLMå“åº”ï¼Œå¼€å§‹å¤„ç†")

            # ä¿å­˜åŸå§‹LLMå“åº” - å¯¹æ‰€æœ‰å†…å®¹ç±»å‹éƒ½è®°å½•
            try:
                # ä½¿ç”¨ä¸è¯·æ±‚ç›¸åŒçš„æ—¶é—´æˆ³ç›®å½•
                response_file = os.path.join(timestamp_dir, f"response_{timestamp}.txt")
                with open(response_file, "w", encoding="utf-8") as f:
                    f.write(result_text)
                logger.info(f"ğŸ“ å·²ä¿å­˜LLMåŸå§‹å“åº”åˆ°: {response_file}")
            except Exception as e:
                logger.warning(f"âš ï¸ æ— æ³•ä¿å­˜LLMåŸå§‹å“åº”: {str(e)}")

            logger.debug(f"LLMåŸå§‹å“åº”å†…å®¹: {result_text[:200]}...")

            # å°è¯•è§£æJSONå“åº”
            if content_type == "roadmap" or content_type == "workflow":
                try:
                    import json

                    # å°è¯•ç›´æ¥è§£æä¸ºJSON
                    try:
                        json_result = json.loads(result_text)
                        logger.info("æˆåŠŸè§£æä¸ºJSONå¯¹è±¡")
                        # å¯¹äºè·¯çº¿å›¾ä¸“é—¨å¤„ç†
                        if content_type == "roadmap":
                            return {"success": True, "content_type": "roadmap", "content": json_result, "raw_response": result_text}  # æ·»åŠ åŸå§‹å“åº”
                    except json.JSONDecodeError as je:
                        # å°è¯•ä»éæ ‡å‡†æ ¼å¼ä¸­æå–JSON
                        logger.warning(f"ç›´æ¥JSONè§£æå¤±è´¥: {str(je)}ï¼Œå°è¯•ä»æ–‡æœ¬æå–JSONéƒ¨åˆ†")
                        # æŸ¥æ‰¾å¯èƒ½çš„JSONéƒ¨åˆ†æ ‡è®°
                        json_start_markers = ["{", "{\n", "```json\n{", "```\n{", "```json\n"]
                        json_end_markers = ["}", "\n}", "}\n```", "}\n", "\n}\n```"]

                        json_extracted = False
                        for start_marker in json_start_markers:
                            if start_marker in result_text:
                                start_index = result_text.find(start_marker)
                                if start_marker not in ["{", "{\n"]:
                                    start_index += len(start_marker) - 1  # å‡å»1æ˜¯ä¸ºäº†ä¿ç•™{

                                # æŸ¥æ‰¾ç»“æŸæ ‡è®°
                                end_index = -1
                                for end_marker in json_end_markers:
                                    if end_marker in result_text[start_index:]:
                                        # è¿™é‡Œ+1æ˜¯ä¸ºäº†åŒ…å«ç»“æŸçš„}
                                        end_index = result_text.find(end_marker, start_index) + 1
                                        break

                                if end_index > start_index:
                                    json_text = result_text[start_index:end_index]
                                    try:
                                        json_result = json.loads(json_text)
                                        logger.info(f"æˆåŠŸä»éƒ¨åˆ†æ–‡æœ¬ä¸­æå–JSONå¯¹è±¡: ä»{start_index}åˆ°{end_index}")
                                        # å¯¹äºè·¯çº¿å›¾ä¸“é—¨å¤„ç†
                                        if content_type == "roadmap":
                                            return {
                                                "success": True,
                                                "content_type": "roadmap",
                                                "content": json_result,
                                                "raw_response": result_text,  # æ·»åŠ åŸå§‹å“åº”
                                            }
                                        json_extracted = True
                                        break
                                    except json.JSONDecodeError as e:
                                        logger.warning(f"æå–çš„JSONéƒ¨åˆ†è§£æå¤±è´¥: {str(e)}, æ–‡æœ¬: {json_text[:50]}...")

                        # å¦‚æœæœªèƒ½æå–JSONï¼ŒæŠŠåŸå§‹å“åº”ä½œä¸ºYAMLå¤„ç†
                        if not json_extracted:
                            logger.warning("æ— æ³•ä»å“åº”ä¸­æå–JSONï¼Œå°è¯•ä½œä¸ºYAMLå¤„ç†")
                            try:
                                import yaml

                                yaml_data = yaml.safe_load(result_text)
                                if isinstance(yaml_data, dict):
                                    logger.info("æˆåŠŸå°†å“åº”è§£æä¸ºYAML")
                                    return {"success": True, "content_type": "roadmap", "content": yaml_data, "raw_response": result_text}  # æ·»åŠ åŸå§‹å“åº”
                            except yaml.YAMLError as ye:
                                logger.warning(f"YAMLè§£æä¹Ÿå¤±è´¥: {str(ye)}")

                            # è¿”å›åŸå§‹æ–‡æœ¬ï¼Œä½œä¸ºå†…å®¹é¢„è§ˆ
                            return {
                                "success": False,
                                "error": f"æ— æ³•è§£æLLMå“åº”ä¸ºJSONæˆ–YAML",
                                "content_type": content_type,
                                "content_preview": result_text[:300] + "..." if len(result_text) > 300 else result_text,
                                "raw_response": result_text,
                            }

                except Exception as e:
                    logger.error(f"å¤„ç†JSONå“åº”æ—¶å‡ºé”™: {str(e)}")
                    return {
                        "success": False,
                        "error": f"å¤„ç†JSONå“åº”å‡ºé”™: {str(e)}",
                        "content_type": content_type,
                        "content_preview": result_text[:300] + "..." if len(result_text) > 300 else result_text,
                        "raw_response": result_text,
                    }

            # æ ¹æ®å†…å®¹ç±»å‹å¤„ç†ç»“æœ
            content_processors = {
                "workflow": self._process_workflow_response,
                "rule": self._process_rule_response,
                "document": self._process_document_response,
                "generic": self._process_generic_response,
            }

            processor = content_processors.get(content_type, self._process_generic_response)
            return processor(content, result_text)

        except Exception as e:
            logger.error(f"LLMæœåŠ¡è°ƒç”¨æˆ–å“åº”å¤„ç†å¤±è´¥: {str(e)}")

            # å³ä½¿å‘ç”Ÿå¼‚å¸¸ï¼Œä¹Ÿåˆ›å»ºä¸€ä¸ªè°ƒè¯•æ–‡ä»¶ï¼Œæ ‡æ˜è§£æå‡ºé”™
            if content_type == "roadmap":
                try:
                    # ä½¿ç”¨é¡¹ç›®ç›®å½•ä¸‹çš„ä¸´æ—¶ç›®å½•
                    llm_log_dir = self.get_temp_dir("llm_logs")

                    error_response_file = os.path.join(llm_log_dir, f"llm_error_response_{int(time.time())}.txt")
                    with open(error_response_file, "w", encoding="utf-8") as f:
                        error_msg = f"LLMè§£æè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {str(e)}\n\n"
                        if result_text:
                            error_msg += f"è·å–åˆ°çš„éƒ¨åˆ†å“åº”:\n{result_text}"
                        else:
                            error_msg += "æœªèƒ½è·å–ä»»ä½•å“åº”ã€‚"
                        f.write(error_msg)
                    logger.info(f"ğŸ“ å·²ä¿å­˜LLMé”™è¯¯ä¿¡æ¯åˆ°: {error_response_file}")
                except Exception as write_err:
                    logger.warning(f"âš ï¸ æ— æ³•ä¿å­˜é”™è¯¯ä¿¡æ¯: {str(write_err)}")

            return {
                "success": False,
                "error": str(e),
                "content_type": content_type,
                "content_preview": content[:100] + "..." if len(content) > 100 else content,
                "raw_response": result_text if result_text else "è§£æè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸ï¼Œæœªèƒ½è·å–å“åº”",
            }

    def _process_workflow_response(self, content: str, result_text: str) -> Dict[str, Any]:
        """å¤„ç†å·¥ä½œæµå“åº”"""
        try:
            # å°è¯•è§£æJSONå“åº”
            workflow_data = json.loads(result_text)

            return {"success": True, "content_type": "workflow", "content": workflow_data}
        except json.JSONDecodeError as e:
            return {
                "success": False,
                "error": f"Failed to parse JSON response: {str(e)}",
                "content_type": "workflow",
                "content_preview": result_text[:100] + "...",
            }

    def _process_rule_response(self, content: str, result_text: str) -> Dict[str, Any]:
        """å¤„ç†è§„åˆ™å“åº”"""
        # ç›´æ¥é€šè¿‡åŸºæœ¬çš„æ–¹æ³•æå–Front Matterå’Œæ ‡é¢˜
        front_matter = {}
        markdown_content = content

        # ç®€å•è§£æFront Matter
        if content.startswith("---"):
            try:
                end_index = content.find("---", 3)
                if end_index != -1:
                    front_matter_text = content[3:end_index].strip()
                    for line in front_matter_text.split("\n"):
                        if ":" in line:
                            key, value = line.split(":", 1)
                            front_matter[key.strip()] = value.strip()

                    markdown_content = content[end_index + 3 :].strip()
            except Exception:
                pass

        # æå–æ ‡é¢˜
        title = ""
        lines = markdown_content.split("\n")
        for line in lines:
            if line.startswith("# "):
                title = line[2:].strip()
                break

        return {
            "success": True,
            "content_type": "rule",
            "front_matter": front_matter,
            "title": title,
            "content": markdown_content,
            "metadata": {
                "title": title,
                "type": front_matter.get("type", "unknown"),
                "description": front_matter.get("description", ""),
                "tags": front_matter.get("tags", "").split(",") if front_matter.get("tags") else [],
            },
        }

    def _process_document_response(self, content: str, result_text: str) -> Dict[str, Any]:
        """å¤„ç†æ–‡æ¡£å“åº”"""
        # æå–æ ‡é¢˜å’Œç›®å½•ç»“æ„
        title = ""
        lines = content.split("\n")
        for line in lines:
            if line.startswith("# "):
                title = line[2:].strip()
                break

        # ç®€å•è§£æç›®å½•ç»“æ„
        headings = []
        for line in lines:
            if line.startswith("#"):
                level = 0
                for char in line:
                    if char == "#":
                        level += 1
                    else:
                        break

                heading_text = line[level:].strip()
                headings.append({"level": level, "text": heading_text})

        return {
            "success": True,
            "content_type": "document",
            "title": title,
            "content": content,
            "structure": {"headings": headings},
            "metadata": {
                "title": title,
                "word_count": len(content.split()),
                "line_count": len(lines),
            },
        }

    def _process_generic_response(self, content: str, result_text: str) -> Dict[str, Any]:
        """å¤„ç†é€šç”¨å“åº”"""
        lines = content.split("\n")

        return {
            "success": True,
            "content_type": "generic",
            "content": content,
            "result": result_text,
            "metadata": {
                "line_count": len(lines),
                "word_count": len(content.split()),
                "char_count": len(content),
            },
        }

    def parse(self, content: str, content_type: Optional[str] = None) -> Dict[str, Any]:
        """
        åŒæ­¥æ–¹æ³•ï¼Œè§£ææ–‡æœ¬å†…å®¹

        è¿™æ˜¯ä¸€ä¸ªé€‚é…æ–¹æ³•ï¼Œå…è®¸åœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­ä½¿ç”¨LLMè§£æå™¨ã€‚
        LLMParseræ€»æ˜¯ä½¿ç”¨LLMæœåŠ¡è¿›è¡Œè§£æï¼Œä¿æŒèŒè´£å•ä¸€ã€‚

        Args:
            content: å¾…è§£æçš„æ–‡æœ¬å†…å®¹
            content_type: å†…å®¹ç±»å‹ï¼Œå¦‚'rule'ã€'document'ç­‰

        Returns:
            è§£æç»“æœ
        """
        import asyncio

        import nest_asyncio

        # å°è¯•å®‰è£…å’Œå¯ç”¨nest_asyncioï¼Œå…è®¸åœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­è¿è¡Œå¼‚æ­¥ä»£ç 
        try:
            nest_asyncio.apply()
        except Exception as e:
            logger.error(f"æ— æ³•å¯ç”¨nest_asyncio: {str(e)}ï¼ŒLLMè§£æå¯èƒ½æ— æ³•åœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­å·¥ä½œ")
            return {
                "success": False,
                "error": f"ç¯å¢ƒé…ç½®é”™è¯¯ï¼Œæ— æ³•å¯ç”¨nest_asyncio: {str(e)}",
                "content_type": content_type or "generic",
                "content_preview": content[:100] + "..." if len(content) > 100 else content,
            }

        try:
            logger.info("ä½¿ç”¨LLMæœåŠ¡è¿›è¡Œè§£æ")

            # ç”Ÿæˆæ—¶é—´æˆ³
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            timestamp_unix = int(time.time())

            # ä½¿ç”¨é¡¹ç›®ç›®å½•ä¸‹çš„ä¸´æ—¶ç›®å½•
            timestamp_dir = self.get_temp_dir("llm_logs")

            # ä¿å­˜è¯·æ±‚å†…å®¹
            request_file = os.path.join(timestamp_dir, f"request_{timestamp_unix}.txt")
            try:
                with open(request_file, "w", encoding="utf-8") as f:
                    # ä¿å­˜è¯¦ç»†è¯·æ±‚å†…å®¹ï¼ŒåŒ…æ‹¬å†…å®¹ç±»å‹å’ŒåŸå§‹å†…å®¹
                    f.write(f"å†…å®¹ç±»å‹: {content_type}\n\n")
                    f.write(f"åŸå§‹å†…å®¹:\n{content}")
                logger.info(f"ğŸ“ å·²ä¿å­˜LLMè¯·æ±‚å†…å®¹åˆ°: {request_file}")
            except Exception as e:
                logger.warning(f"âš ï¸ æ— æ³•ä¿å­˜LLMè¯·æ±‚å†…å®¹: {str(e)}")

            # ä½¿ç”¨asyncioè¿è¡Œå¼‚æ­¥å‡½æ•°
            loop = asyncio.get_event_loop()
            result = loop.run_until_complete(self.parse_text(content, content_type))

            # ä¿å­˜å“åº”å†…å®¹
            response_file = os.path.join(timestamp_dir, f"response_{timestamp_unix}.txt")
            try:
                with open(response_file, "w", encoding="utf-8") as f:
                    if "raw_response" in result:
                        f.write(result["raw_response"])
                    else:
                        import json

                        f.write(json.dumps(result, indent=2, ensure_ascii=False))
                logger.info(f"ğŸ“ å·²ä¿å­˜LLMå“åº”å†…å®¹åˆ°: {response_file}")
            except Exception as e:
                logger.warning(f"âš ï¸ æ— æ³•ä¿å­˜LLMå“åº”å†…å®¹: {str(e)}")

            return result
        except Exception as e:
            logger.error(f"âŒ LLMè§£æå¤±è´¥: {str(e)}")

            error_result = {
                "success": False,
                "error": f"LLMè§£æå¤±è´¥: {str(e)}",
                "content_type": content_type or "generic",
                "content_preview": content[:100] + "..." if len(content) > 100 else content,
                "original_error": str(e),
            }

            # ä¿å­˜é”™è¯¯ä¿¡æ¯
            try:
                # ä½¿ç”¨é¡¹ç›®ç›®å½•ä¸‹çš„ä¸´æ—¶ç›®å½•
                timestamp_dir = self.get_temp_dir("llm_logs")
                error_file = os.path.join(timestamp_dir, f"llm_parser_error_{timestamp_unix}.json")
                with open(error_file, "w", encoding="utf-8") as f:
                    json.dump(error_result, f, indent=2, ensure_ascii=False)
                logger.info(f"ğŸ“ å·²ä¿å­˜è§£æé”™è¯¯ä¿¡æ¯åˆ°: {error_file}")
            except Exception as write_err:
                logger.warning(f"âš ï¸ æ— æ³•ä¿å­˜è§£æé”™è¯¯æ–‡ä»¶: {str(write_err)}")

            return error_result
