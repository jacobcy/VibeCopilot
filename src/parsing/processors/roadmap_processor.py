"""
è·¯çº¿å›¾å¤„ç†å™¨

ç”¨äºè·¯çº¿å›¾æ•°æ®çš„æ™ºèƒ½è§£æå’Œç»“æ„è½¬æ¢ï¼Œä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
1. å°†ä¸è§„èŒƒçš„YAMLè½¬æ¢ä¸ºæ­£ç¡®çš„è·¯çº¿å›¾ç»“æ„
2. å°†milestoneæ ¼å¼è½¬æ¢ä¸ºepic-story-taskç»“æ„
3. ä¿®å¤å¸¸è§çš„ç»“æ„é—®é¢˜
"""

import json
import logging
import os
import time
from typing import Any, Dict, Optional, Tuple

import yaml

from src.llm.service_factory import create_llm_service
from src.validation.roadmap_validation import RoadmapValidator

logger = logging.getLogger(__name__)

# å®šä¹‰é¡¹ç›®æ ¹ç›®å½•å’Œä¸´æ—¶ç›®å½•å¸¸é‡
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
TEMP_ROOT = os.path.join(PROJECT_ROOT, "temp")


class RoadmapProcessor:
    """è·¯çº¿å›¾æ•°æ®å¤„ç†å™¨ - ä»…ä½¿ç”¨LLMè§£æ"""

    def __init__(self):
        """åˆå§‹åŒ–è·¯çº¿å›¾å¤„ç†å™¨"""
        # åˆ›å»ºLLMæœåŠ¡å®ä¾‹
        config = {"provider": "openai", "format": "yaml", "content_type": "roadmap"}
        self.llm_service = create_llm_service("openai", config)

        # åˆå§‹åŒ–éªŒè¯å™¨
        try:
            self.validator = RoadmapValidator()
        except Exception as e:
            logger.warning(f"åˆå§‹åŒ–éªŒè¯å™¨å¤±è´¥: {str(e)}ï¼Œå°†ä½¿ç”¨None")
            self.validator = None

        # æ·»åŠ å­—æ®µæ˜ å°„å’Œä¼˜å…ˆçº§è½¬æ¢çš„å­—å…¸
        self.priority_map = {
            "P0": "critical",
            "P1": "high",
            "P2": "medium",
            "P3": "low",
            "highest": "critical",
            "higher": "high",
            "normal": "medium",
            "lower": "low",
            "lowest": "low",
        }

        # æ—¶é—´æˆ³ç›®å½•ï¼Œç”¨äºä¸´æ—¶æ–‡ä»¶
        self._timestamp_dir = None

        # ç³»ç»Ÿæç¤º
        self.system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è·¯çº¿å›¾ç»“æ„åŒ–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ä»”ç»†åˆ†ææä¾›çš„è·¯çº¿å›¾YAMLå†…å®¹
2. å°†å†…å®¹è½¬æ¢ä¸ºæ ‡å‡†çš„epic-story-taskç»“æ„
3. ç¡®ä¿è¾“å‡ºåŒ…å«å®Œæ•´çš„metadataéƒ¨åˆ†ï¼ˆå¿…é¡»åŒ…å«ï¼‰ï¼Œè‡³å°‘è¦æœ‰titleå’Œversionå­—æ®µ
4. ç¡®ä¿æ‰€æœ‰å­—æ®µåå’Œå€¼ç¬¦åˆæ ‡å‡†æ ¼å¼
5. ç‰¹åˆ«æ³¨æ„å°†milestoneç»“æ„è½¬æ¢ä¸ºepic-storyç»“æ„
6. ç¡®ä¿priorityå­—æ®µä½¿ç”¨æ ‡å‡†å€¼(low, medium, high, critical)
7. è¾“å‡ºçš„æ ‡å‡†ç»“æ„å¿…é¡»åŒ…å«ä»¥ä¸‹å¿…è¦å­—æ®µï¼š
   - metadataéƒ¨åˆ†ï¼šåŒ…å«titleå’Œversionå­—æ®µ
   - epicsæ•°ç»„ï¼šåŒ…å«titleå’Œstorieså­—æ®µ
   - æ¯ä¸ªepicä¸‹çš„storiesæ•°ç»„ï¼šæ¯ä¸ªstoryè‡³å°‘åŒ…å«titleå­—æ®µå’Œä¸€ä¸ªtasksæ•°ç»„
   - æ¯ä¸ªstoryçš„tasksæ•°ç»„ï¼šæ¯ä¸ªtaskè‡³å°‘åŒ…å«titleå­—æ®µå’Œstatuså­—æ®µ
8. å°†ç»“æœä»¥JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡æœ¬
9. ç¡®ä¿è¾“å‡ºçš„JSONæ ¼å¼å®Œå…¨ç¬¦åˆè¦æ±‚çš„ç»“æ„"""

    def get_temp_file(self, filename: str) -> str:
        """è·å–ä¸´æ—¶æ–‡ä»¶è·¯å¾„"""
        if not self._timestamp_dir:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            roadmap_dir = os.path.join(TEMP_ROOT, "roadmap")
            os.makedirs(roadmap_dir, exist_ok=True)
            self._timestamp_dir = os.path.join(roadmap_dir, timestamp)
            os.makedirs(self._timestamp_dir, exist_ok=True)

        return os.path.join(self._timestamp_dir, filename)

    async def parse_roadmap(self, content: str) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè§£æè·¯çº¿å›¾å†…å®¹"""
        # ä¿å­˜åŸå§‹å†…å®¹ç”¨äºè°ƒè¯•
        debug_file = self.get_temp_file("original_yaml_content.yaml")
        try:
            with open(debug_file, "w", encoding="utf-8") as f:
                f.write(content)
            logger.info(f"ğŸ“ å·²ä¿å­˜åŸå§‹YAMLå†…å®¹åˆ°: {debug_file}")
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•ä¿å­˜åŸå§‹å†…å®¹è°ƒè¯•æ–‡ä»¶: {str(e)}")

        logger.info("ğŸš€ ä½¿ç”¨LLMè§£æroadmap")

        # å‡†å¤‡æ¶ˆæ¯ - ä½¿ç”¨éå¸¸ç®€æ´çš„æ–¹å¼
        user_message = "è¯·å°†ä»¥ä¸‹è·¯çº¿å›¾å†…å®¹è§£æä¸ºæ ‡å‡†ç»“æ„ï¼š\n\n" + content + "\n\n"

        # æ·»åŠ è¦æ±‚è¿”å›JSONå†…å®¹çš„ä¿¡æ¯
        user_message += "è¯·å°†å†…å®¹è½¬æ¢ä¸ºæ ‡å‡†çš„epic-story-taskç»“æ„ï¼Œå¹¶ç¡®ä¿åŒ…å«metadataéƒ¨åˆ†ã€‚\n"
        user_message += "è¾“å‡ºæ ¼å¼åº”ä¸ºJSONï¼ŒåŒ…å«metadataï¼ˆè‡³å°‘æœ‰titleå’Œversionå­—æ®µï¼‰å’Œepicsæ•°ç»„ã€‚\n"
        user_message += "æ¯ä¸ªepicåº”åŒ…å«è‡³å°‘titleå’Œstorieså­—æ®µã€‚\n"
        user_message += "æ¯ä¸ªstoryå¿…é¡»åŒ…å«titleå­—æ®µå’Œtasksæ•°ç»„ï¼Œå³ä½¿tasksä¸ºç©ºä¹Ÿè¦æä¾›è¯¥æ•°ç»„ã€‚\n"
        user_message += "æ¯ä¸ªtaskè‡³å°‘åº”åŒ…å«titleå’Œstatuså­—æ®µã€‚\n"
        user_message += "ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡æœ¬ï¼Œåªè¾“å‡ºJSONå†…å®¹ã€‚"

        # å¼•ç”¨ç®€å•ç¤ºä¾‹
        user_message += '\n\nç»“æ„ç¤ºä¾‹ï¼š{"metadata":{"title":"...","version":"..."},"epics":[{"title":"...","stories":[{"title":"...","tasks":[{"title":"...","status":"..."}]}]}]}'

        messages = [{"role": "system", "content": self.system_prompt}, {"role": "user", "content": user_message}]

        # ä¿å­˜è¯·æ±‚å†…å®¹
        request_file = self.get_temp_file("roadmap_llm_request.yaml")
        try:
            with open(request_file, "w", encoding="utf-8") as f:
                f.write(content)
            logger.info(f"ğŸ“ å·²ä¿å­˜å‘é€ç»™LLMçš„åŸå§‹è¯·æ±‚å†…å®¹åˆ°: {request_file}")
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•ä¿å­˜LLMè¯·æ±‚å†…å®¹: {str(e)}")

        # è°ƒç”¨LLMæœåŠ¡
        try:
            logger.info("ğŸš€ å¼€å§‹è°ƒç”¨LLMæœåŠ¡...")
            response = await self.llm_service.chat_completion(messages)
            logger.info("âœ… LLMæœåŠ¡è°ƒç”¨æˆåŠŸ")

            # å¤„ç†å“åº”
            if hasattr(response, "choices") and hasattr(response.choices[0], "message"):
                # OpenAI APIçš„åŸç”Ÿå¯¹è±¡æ ¼å¼
                result_text = response.choices[0].message.content
            else:
                # å­—å…¸æ ¼å¼çš„å“åº”
                result_text = response["choices"][0]["message"]["content"]

            # ä¿å­˜LLMå®Œæ•´åŸå§‹å“åº”ä»¥ä¾¿è°ƒè¯•
            raw_response_file = self.get_temp_file("llm_response_result.json")
            try:
                with open(raw_response_file, "w", encoding="utf-8") as f:
                    f.write(result_text)
                logger.info(f"ğŸ“ å·²ä¿å­˜LLMå®Œæ•´åŸå§‹å“åº”åˆ°: {raw_response_file}")
            except Exception as e:
                logger.warning(f"âš ï¸ æ— æ³•ä¿å­˜LLMå®Œæ•´åŸå§‹å“åº”: {str(e)}")

            # ä»LLMå“åº”ä¸­æå–JSONæ•°æ®
            processed_data = self._extract_processed_data(result_text)

            if processed_data is None:
                return self._generate_error_result("æ— æ³•ä»LLMå“åº”ä¸­æå–æœ‰æ•ˆæ•°æ®")

            # ç¡®ä¿æœ‰metadataéƒ¨åˆ†
            if "metadata" not in processed_data:
                processed_data["metadata"] = {"title": "è·¯çº¿å›¾", "version": "1.0", "description": "ä½¿ç”¨LLMè§£æç”Ÿæˆ"}
                logger.warning("âš ï¸ æ·»åŠ ç¼ºå¤±çš„metadataéƒ¨åˆ†")

            # ä¿®å¤å­—æ®µæ˜ å°„ã€ä¼˜å…ˆçº§æ ¼å¼å’Œç©ºçŠ¶æ€å€¼
            processed_data = self.fix_field_mapping(processed_data)
            processed_data = self.fix_priority_format(processed_data)
            processed_data = self.fix_empty_status(processed_data)

            # ä¿å­˜å¤„ç†åçš„æ•°æ®
            processed_file = self.get_temp_file("roadmap_llm_processed_data.json")
            try:
                with open(processed_file, "w", encoding="utf-8") as f:
                    json.dump(processed_data, f, indent=2, ensure_ascii=False)
                logger.info(f"ğŸ“ å·²ä¿å­˜å¤„ç†åçš„æ•°æ®åˆ°: {processed_file}")
            except Exception as e:
                logger.warning(f"âš ï¸ æ— æ³•ä¿å­˜å¤„ç†åçš„æ•°æ®: {str(e)}")

            # å¯¹LLMè§£æç»“æœè¿›è¡ŒéªŒè¯
            is_valid = self.validator and self.validator.validate(processed_data)

            if is_valid:
                logger.info("âœ… LLMè§£æç»“æœéªŒè¯é€šè¿‡")
                return processed_data
            else:
                # è®°å½•éªŒè¯å¤±è´¥çš„è¯¦æƒ…ä½†ä»è¿”å›æ•°æ®
                warnings = self.validator.get_warnings() if self.validator else []
                errors = self.validator.get_errors() if self.validator else ["æ²¡æœ‰éªŒè¯å™¨å®ä¾‹"]
                logger.warning(f"âš ï¸ LLMè§£ææˆåŠŸä½†éªŒè¯å¤±è´¥: {len(errors)}ä¸ªé”™è¯¯, {len(warnings)}ä¸ªè­¦å‘Š")
                return processed_data

        except Exception as e:
            return self._handle_exception(e)

    def _extract_processed_data(self, result_text: str) -> Optional[Dict[str, Any]]:
        """ä»LLMå“åº”ä¸­æå–æœ‰æ•ˆæ•°æ®"""
        processed_data = None

        # å°è¯•ç›´æ¥è§£æä¸ºJSON
        try:
            processed_data = json.loads(result_text)
            if isinstance(processed_data, dict):
                logger.info("âœ… æˆåŠŸå°†LLMå“åº”è§£æä¸ºJSONå¯¹è±¡")
                return processed_data
        except json.JSONDecodeError:
            logger.warning("âš ï¸ ç›´æ¥JSONè§£æå¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†")

        # å°è¯•ä»å“åº”ä¸­æå–JSONéƒ¨åˆ†
        json_start_markers = ["{", "{\n", "```json\n{", "```\n{", "```json\n"]
        json_end_markers = ["}", "\n}", "}\n```", "}\n", "\n}\n```"]

        for start_marker in json_start_markers:
            if start_marker in result_text:
                start_index = result_text.find(start_marker)
                if start_marker not in ["{", "{\n"]:
                    start_index += len(start_marker) - 1  # å‡å»1æ˜¯ä¸ºäº†ä¿ç•™{

                # æŸ¥æ‰¾ç»“æŸæ ‡è®°
                end_index = -1
                for end_marker in json_end_markers:
                    if end_marker in result_text[start_index:]:
                        # è¿™é‡Œ+1æ˜¯ä¸ºäº†åŒ…å«ç»“æŸçš„}
                        end_index = result_text.find(end_marker, start_index) + 1
                        break

                if end_index > start_index:
                    json_text = result_text[start_index:end_index]
                    try:
                        processed_data = json.loads(json_text)
                        if isinstance(processed_data, dict):
                            logger.info(f"âœ… æˆåŠŸä»éƒ¨åˆ†æ–‡æœ¬ä¸­æå–JSONå¯¹è±¡")
                            return processed_data
                    except json.JSONDecodeError:
                        logger.warning("âš ï¸ æå–çš„JSONéƒ¨åˆ†è§£æå¤±è´¥")

        # å°è¯•ä½œä¸ºYAMLè§£æ
        try:
            yaml_data = yaml.safe_load(result_text)
            if isinstance(yaml_data, dict):
                logger.info("âœ… æˆåŠŸå°†å“åº”è§£æä¸ºYAML")
                return yaml_data
        except Exception:
            logger.warning("âš ï¸ YAMLè§£æä¹Ÿå¤±è´¥")

        return None

    def _generate_error_result(self, error_message: str) -> Dict[str, Any]:
        """ç”Ÿæˆé”™è¯¯ç»“æœ"""
        logger.error(f"âŒ {error_message}")

        # ç”Ÿæˆé”™è¯¯ç»“æœ
        error_result = {"metadata": {"title": "LLMè§£æå¤±è´¥", "description": error_message, "version": "0.1", "error": True}, "epics": []}

        return error_result

    def _handle_exception(self, e: Exception) -> Dict[str, Any]:
        """å¤„ç†å¼‚å¸¸"""
        import traceback

        error_message = f"LLMè§£æè¿‡ç¨‹å‡ºç°å¼‚å¸¸: {str(e)}"
        logger.error(f"âŒ {error_message}")

        # è·å–å¼‚å¸¸å †æ ˆ
        error_traceback = traceback.format_exc()

        # ä¿å­˜å¼‚å¸¸ä¿¡æ¯
        error_file = self.get_temp_file("roadmap_llm_exception.txt")
        try:
            with open(error_file, "w", encoding="utf-8") as f:
                f.write(f"å¼‚å¸¸ä¿¡æ¯: {str(e)}\n\nè¯¦ç»†å †æ ˆ:\n{error_traceback}")
            logger.info(f"ğŸ“ å·²ä¿å­˜å¼‚å¸¸è¯¦ç»†ä¿¡æ¯åˆ°: {error_file}")
        except Exception as write_err:
            logger.warning(f"âš ï¸ æ— æ³•ä¿å­˜å¼‚å¸¸ä¿¡æ¯æ–‡ä»¶: {str(write_err)}")

        # è¿”å›é”™è¯¯ç»“æœ
        return {
            "metadata": {
                "title": "è·¯çº¿å›¾è§£æå¼‚å¸¸",
                "description": error_message,
                "version": "0.1",
                "error": True,
                "error_details": error_traceback.split("\n")[:5],  # åŒ…å«å‰5è¡Œå¼‚å¸¸å †æ ˆ
            },
            "epics": [],
        }

    def fix_field_mapping(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ä¿®å¤å­—æ®µæ˜ å°„ï¼Œå¤„ç†ä¸åŒå‘½åè§„èŒƒä¹‹é—´çš„è½¬æ¢"""
        # å­—æ®µåç§°æ˜ å°„è¡¨
        field_map = {"name": "title", "desc": "description", "description": "description", "owner": "assignee", "priority": "priority"}

        # å¦‚æœæœ‰epicså­—æ®µï¼Œå¤„ç†æ¯ä¸ªepic
        if "epics" in data and isinstance(data["epics"], list):
            for epic in data["epics"]:
                # å¤„ç†epicçš„å­—æ®µæ˜ å°„
                for old_field, new_field in field_map.items():
                    if old_field in epic and old_field != new_field:
                        epic[new_field] = epic.pop(old_field)

                # å¦‚æœæœ‰storieså­—æ®µï¼Œå¤„ç†æ¯ä¸ªstory
                if "stories" in epic and isinstance(epic["stories"], list):
                    for story in epic["stories"]:
                        # å¤„ç†storyçš„å­—æ®µæ˜ å°„
                        for old_field, new_field in field_map.items():
                            if old_field in story and old_field != new_field:
                                story[new_field] = story.pop(old_field)

                        # å¦‚æœæœ‰taskså­—æ®µï¼Œå¤„ç†æ¯ä¸ªtask
                        if "tasks" in story and isinstance(story["tasks"], list):
                            for task in story["tasks"]:
                                # å¤„ç†taskçš„å­—æ®µæ˜ å°„
                                for old_field, new_field in field_map.items():
                                    if old_field in task and old_field != new_field:
                                        task[new_field] = task.pop(old_field)

        return data

    def fix_empty_status(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ä¿®å¤ç©ºæ•°ç»„å’ŒçŠ¶æ€å€¼é—®é¢˜"""
        if "epics" not in data or not data["epics"]:
            # å¦‚æœepicsä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œæ·»åŠ ä¸€ä¸ªé»˜è®¤çš„epic
            data["epics"] = [{"title": "é»˜è®¤åŠŸèƒ½æ¨¡å—", "description": "è‡ªåŠ¨åˆ›å»ºçš„åŠŸèƒ½æ¨¡å—", "stories": []}]
            logger.warning("âš ï¸ æ·»åŠ é»˜è®¤epicï¼Œå› ä¸ºepicsæ•°ç»„ä¸ºç©º")

        for epic_index, epic in enumerate(data["epics"]):
            # ç¡®ä¿epicæœ‰storieså­—æ®µä¸”ä¸ä¸ºç©º
            if "stories" not in epic or not epic["stories"]:
                epic["stories"] = [{"title": f"{epic.get('title', 'æ¨¡å—')}çš„é»˜è®¤æ•…äº‹", "status": "planned", "priority": "medium", "tasks": []}]
                logger.warning(f"âš ï¸ ä¸ºEpic #{epic_index+1} '{epic.get('title', 'æœªå‘½å')}' æ·»åŠ é»˜è®¤story")

            for story_index, story in enumerate(epic["stories"]):
                # ç¡®ä¿storyæœ‰taskså­—æ®µä¸”ä¸ä¸ºç©º
                if "tasks" not in story or not story["tasks"]:
                    story["tasks"] = [{"title": f"{story.get('title', 'æ•…äº‹')}çš„é»˜è®¤ä»»åŠ¡", "status": "todo"}]
                    logger.warning(f"âš ï¸ ä¸ºStory #{story_index+1} '{story.get('title', 'æœªå‘½å')}' æ·»åŠ é»˜è®¤task")

                for task in story["tasks"]:
                    # ç¡®ä¿taskæœ‰statuså­—æ®µä¸”å€¼æœ‰æ•ˆ
                    if "status" not in task or task["status"] == "" or task["status"] not in ["todo", "in_progress", "done", "completed"]:
                        task["status"] = "todo"
                        logger.warning(f"âš ï¸ ä¿®å¤task '{task.get('title', 'æœªå‘½å')}' çš„statuså€¼ä¸º'todo'")

                    # ç¡®ä¿taskæœ‰titleå­—æ®µ
                    if "title" not in task or not task["title"]:
                        task["title"] = "è‡ªåŠ¨åˆ›å»ºçš„ä»»åŠ¡"
                        logger.warning("âš ï¸ ä¸ºtaskæ·»åŠ é»˜è®¤title")

        return data

    def fix_priority_format(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ä¿®å¤ä¼˜å…ˆçº§æ ¼å¼ï¼Œå°†P0/P1/P2æ ¼å¼è½¬æ¢ä¸ºlow/medium/high/critical"""
        # å¦‚æœæœ‰epicså­—æ®µï¼Œå¤„ç†æ¯ä¸ªepic
        if "epics" in data and isinstance(data["epics"], list):
            for epic in data["epics"]:
                # å¤„ç†epicçš„ä¼˜å…ˆçº§
                if "priority" in epic and epic["priority"] in self.priority_map:
                    epic["priority"] = self.priority_map[epic["priority"]]

                # å¦‚æœæœ‰storieså­—æ®µï¼Œå¤„ç†æ¯ä¸ªstory
                if "stories" in epic and isinstance(epic["stories"], list):
                    for story in epic["stories"]:
                        # å¤„ç†storyçš„ä¼˜å…ˆçº§
                        if "priority" in story and story["priority"] in self.priority_map:
                            story["priority"] = self.priority_map[story["priority"]]

                        # å¦‚æœæœ‰taskså­—æ®µï¼Œå¤„ç†æ¯ä¸ªtask
                        if "tasks" in story and isinstance(story["tasks"], list):
                            for task in story["tasks"]:
                                # å¤„ç†taskçš„ä¼˜å…ˆçº§
                                if "priority" in task and task["priority"] in self.priority_map:
                                    task["priority"] = self.priority_map[task["priority"]]

        return data

    def process_file(self, file_path: str) -> Dict[str, Any]:
        """å¤„ç†è·¯çº¿å›¾YAMLæ–‡ä»¶"""
        logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path}")

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # è·å–æˆ–åˆ›å»ºäº‹ä»¶å¾ªç¯
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

            # ä½¿ç”¨äº‹ä»¶å¾ªç¯è¿è¡Œå¼‚æ­¥å‡½æ•°
            if loop.is_running():
                result = loop.run_until_complete(self.parse_roadmap(content))
            else:
                result = asyncio.run(self.parse_roadmap(content))

            logger.info("æ–‡ä»¶å¤„ç†æˆåŠŸ")
            return result

        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {str(e)}")
            raise

    async def fix_file(self, file_path: str, output_path: Optional[str] = None) -> Tuple[bool, str]:
        """ä¿®å¤è·¯çº¿å›¾YAMLæ–‡ä»¶"""
        logger.info(f"å¼€å§‹ä¿®å¤æ–‡ä»¶: {file_path}")

        if not output_path:
            basename = os.path.basename(file_path)
            name, ext = os.path.splitext(basename)
            output_path = os.path.join(os.path.dirname(file_path), f"{name}_fixed{ext}")

        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # ç›´æ¥è°ƒç”¨å¼‚æ­¥è§£ææ–¹æ³•
            data = await self.parse_roadmap(content)

            # éªŒè¯å¤„ç†åçš„æ•°æ®
            is_valid = self.validator.validate(data) if self.validator else True

            if not is_valid and self.validator:
                warnings_str = "\n".join(self.validator.get_warnings())
                errors_str = "\n".join(self.validator.get_errors())
                logger.warning(f"ä¿®å¤åçš„æ•°æ®ä»æœ‰é—®é¢˜:\nè­¦å‘Š:\n{warnings_str}\né”™è¯¯:\n{errors_str}")

            # å†™å…¥è¾“å‡ºæ–‡ä»¶
            with open(output_path, "w", encoding="utf-8") as f:
                yaml.dump(data, f, default_flow_style=False, allow_unicode=True, sort_keys=False)

            logger.info(f"æˆåŠŸä¿®å¤æ–‡ä»¶å¹¶ä¿å­˜åˆ°: {output_path}")
            return True, output_path

        except Exception as e:
            error_msg = f"ä¿®å¤æ–‡ä»¶å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, error_msg


# å¯¼å‡ºç±»
__all__ = ["RoadmapProcessor"]
