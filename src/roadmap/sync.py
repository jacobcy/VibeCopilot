"""
æ•°æ®åº“åŒæ­¥æ¨¡å—

æä¾›æ•°æ®åº“ä¸æ–‡ä»¶ç³»ç»Ÿã€GitHubä¹‹é—´çš„åŒæ­¥åŠŸèƒ½ï¼Œ
ç¡®ä¿ä¸åŒæ•°æ®æºä¹‹é—´çš„ä¸€è‡´æ€§ã€‚
"""

import json
import logging
import os
import shutil
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import yaml

from .service import DatabaseService

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


class DataSynchronizer:
    """æ•°æ®åŒæ­¥å™¨ï¼Œè´Ÿè´£æ•°æ®åº“ã€æ–‡ä»¶ç³»ç»Ÿå’ŒGitHubä¹‹é—´çš„åŒæ­¥"""

    def __init__(self, db_service: DatabaseService, project_root: Optional[str] = None):
        """
        åˆå§‹åŒ–åŒæ­¥å™¨

        Args:
            db_service: æ•°æ®åº“æœåŠ¡
            project_root: é¡¹ç›®æ ¹ç›®å½•
        """
        self.db = db_service
        self.project_root = project_root or os.environ.get("PROJECT_ROOT", os.getcwd())
        self.ai_dir = os.path.join(self.project_root, ".ai")

    def _ensure_directory(self, directory: str) -> None:
        """ç¡®ä¿ç›®å½•å­˜åœ¨"""
        os.makedirs(directory, exist_ok=True)

    # ===== æ•°æ®åº“åˆ°æ–‡ä»¶ç³»ç»ŸåŒæ­¥ =====

    def sync_task_to_filesystem(self, task_id: str) -> Optional[str]:
        """
        å°†ä»»åŠ¡åŒæ­¥åˆ°æ–‡ä»¶ç³»ç»Ÿ

        Args:
            task_id: ä»»åŠ¡ID

        Returns:
            ä»»åŠ¡ç›®å½•è·¯å¾„ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        # è·å–ä»»åŠ¡æ•°æ®
        task_data = self.db.get_task(task_id)
        if not task_data:
            logger.error(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            return None

        # æ„å»ºä»»åŠ¡ç›®å½•è·¯å¾„
        task_dir = os.path.join(self.ai_dir, "tasks", task_id)
        self._ensure_directory(task_dir)

        # åˆ›å»ºå­ç›®å½•
        for subdir in ["test", "review", "commit"]:
            self._ensure_directory(os.path.join(task_dir, subdir))

        # åˆ›å»ºä»»åŠ¡æ–‡ä»¶
        task_file = os.path.join(task_dir, "task.md")

        # å‡†å¤‡Markdownå†…å®¹
        content = f"""---
id: {task_data['id']}
title: {task_data['title']}
story_id: {task_data.get('story_id', '')}
status: {task_data['status']}
priority: {task_data['priority']}
estimate: {task_data.get('estimate', 8)}
assignee: {task_data.get('assignee', '')}
tags: {json.dumps(task_data.get('labels', []))}
created_at: {task_data.get('created_at', datetime.now().isoformat())}
---

# {task_data['title']}

## ä»»åŠ¡æè¿°

{task_data.get('description', 'å¾…è¡¥å……')}

## è¯¦ç»†éœ€æ±‚

1. å¾…å®šéœ€æ±‚1
2. å¾…å®šéœ€æ±‚2
3. å¾…å®šéœ€æ±‚3

## æŠ€æœ¯è¦ç‚¹

1. å¾…å®šæŠ€æœ¯ç‚¹1
2. å¾…å®šæŠ€æœ¯ç‚¹2
3. å¾…å®šæŠ€æœ¯ç‚¹3

## éªŒæ”¶æ ‡å‡†

1. å¾…å®šéªŒæ”¶æ ‡å‡†1
2. å¾…å®šéªŒæ”¶æ ‡å‡†2
3. å¾…å®šéªŒæ”¶æ ‡å‡†3

## ç›¸å…³æ–‡æ¡£

- [ç›¸å…³æ–‡æ¡£1](#)
- [ç›¸å…³æ–‡æ¡£2](#)

## ä¾èµ–ä»»åŠ¡

æ— 

## å­ä»»åŠ¡

1. å¾…å®šå­ä»»åŠ¡1
2. å¾…å®šå­ä»»åŠ¡2
"""

        # å†™å…¥æ–‡ä»¶
        with open(task_file, "w", encoding="utf-8") as f:
            f.write(content)

        logger.info(f"ä»»åŠ¡å·²åŒæ­¥åˆ°æ–‡ä»¶ç³»ç»Ÿ: {task_id}")
        return task_dir

    def sync_story_to_filesystem(self, story_id: str) -> Optional[str]:
        """
        å°†æ•…äº‹åŒæ­¥åˆ°æ–‡ä»¶ç³»ç»Ÿ

        Args:
            story_id: æ•…äº‹ID

        Returns:
            æ•…äº‹æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        # è·å–æ•…äº‹æ•°æ®
        story_data = self.db.get_story(story_id)
        if not story_data:
            logger.error(f"æ•…äº‹ä¸å­˜åœ¨: {story_id}")
            return None

        # æ„å»ºæ•…äº‹ç›®å½•è·¯å¾„
        stories_dir = os.path.join(self.ai_dir, "stories")
        self._ensure_directory(stories_dir)

        # åˆ›å»ºæ•…äº‹æ–‡ä»¶
        story_file = os.path.join(stories_dir, f"{story_id}.md")

        # å‡†å¤‡Markdownå†…å®¹
        content = f"""---
id: "{story_data['id']}"
title: "{story_data['title']}"
status: "{story_data['status']}"
progress: {story_data['progress']}
"""

        # å¦‚æœæœ‰epicå…³è”åˆ™æ·»åŠ 
        if story_data.get("epic_id"):
            content += f'epic: "{story_data["epic_id"]}"\n'

        content += f"""created_at: "{story_data.get('created_at', datetime.now().isoformat())}"
updated_at: "{story_data.get('updated_at', datetime.now().isoformat())}"
---

# {story_data['title']}

## æ¦‚è¿°

{story_data.get('description', 'å¾…è¡¥å……')}

## è¯¦æƒ…

è¯¥æ•…äº‹åŒ…å«ä»¥ä¸‹ä¸»è¦å†…å®¹ï¼š

1. **å¾…å®šéƒ¨åˆ†1** - çŠ¶æ€: å¾…å®š
   - å¾…å®šå­ä»»åŠ¡1
   - å¾…å®šå­ä»»åŠ¡2

2. **å¾…å®šéƒ¨åˆ†2** - çŠ¶æ€: å¾…å®š
   - å¾…å®šå­ä»»åŠ¡1
   - å¾…å®šå­ä»»åŠ¡2

## ç›¸å…³ä»»åŠ¡

- ğŸš§ ä»»åŠ¡ID: å¾…å®š
  - ğŸš§ çŠ¶æ€: å¾…å®š
  - ğŸš§ è¿›åº¦: 0%

## å…³è”ä¿¡æ¯

- é‡Œç¨‹ç¢‘: {story_id if story_id.startswith('M') else 'æ— '}
- ä¼˜å…ˆçº§: {story_data.get('priority', 'P2')}
- å¼€å‘è€…:

> è¯¥æ•…äº‹æ˜¯ä»æ•°æ®åº“è‡ªåŠ¨ç”Ÿæˆçš„
"""

        # å†™å…¥æ–‡ä»¶
        with open(story_file, "w", encoding="utf-8") as f:
            f.write(content)

        logger.info(f"æ•…äº‹å·²åŒæ­¥åˆ°æ–‡ä»¶ç³»ç»Ÿ: {story_id}")
        return story_file

    def sync_all_to_filesystem(self) -> Tuple[int, int]:
        """
        å°†æ‰€æœ‰æ•°æ®åŒæ­¥åˆ°æ–‡ä»¶ç³»ç»Ÿ

        Returns:
            åŒæ­¥çš„æ•…äº‹å’Œä»»åŠ¡æ•°é‡
        """
        # è·å–æ‰€æœ‰æ•…äº‹å’Œä»»åŠ¡
        stories = self.db.list_stories()
        tasks = self.db.list_tasks()

        # åŒæ­¥æ•…äº‹
        story_count = 0
        for story in stories:
            story_id = story["id"]
            if self.sync_story_to_filesystem(story_id):
                story_count += 1

        # åŒæ­¥ä»»åŠ¡
        task_count = 0
        for task in tasks:
            task_id = task["id"]
            if self.sync_task_to_filesystem(task_id):
                task_count += 1

        logger.info(f"æ‰€æœ‰æ•°æ®å·²åŒæ­¥åˆ°æ–‡ä»¶ç³»ç»Ÿ: {story_count}ä¸ªæ•…äº‹, {task_count}ä¸ªä»»åŠ¡")
        return story_count, task_count

    def sync_to_roadmap_yaml(self, output_path: Optional[str] = None) -> str:
        """
        å°†æ•°æ®åº“æ•°æ®åŒæ­¥åˆ°roadmap.yaml

        Args:
            output_path: è¾“å‡ºè·¯å¾„ï¼Œé»˜è®¤ä¸º.ai/roadmap/current.yaml

        Returns:
            ç”Ÿæˆçš„YAMLæ–‡ä»¶è·¯å¾„
        """
        # å¯¼å‡ºæ•°æ®
        roadmap_data = self.db.export_to_yaml()

        # é»˜è®¤è¾“å‡ºè·¯å¾„
        if not output_path:
            output_path = os.path.join(self.ai_dir, "roadmap", "current.yaml")

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        # å†™å…¥YAMLæ–‡ä»¶
        with open(output_path, "w", encoding="utf-8") as f:
            yaml.dump(roadmap_data, f, default_flow_style=False, allow_unicode=True)

        logger.info(f"æ•°æ®å·²åŒæ­¥åˆ°YAML: {output_path}")
        return output_path

    # ===== æ–‡ä»¶ç³»ç»Ÿåˆ°æ•°æ®åº“åŒæ­¥ =====

    def sync_from_roadmap_yaml(self, yaml_path: Optional[str] = None) -> Tuple[int, int, int]:
        """
        ä»roadmap.yamlåŒæ­¥æ•°æ®åˆ°æ•°æ®åº“

        Args:
            yaml_path: YAMLæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º.ai/roadmap/current.yaml

        Returns:
            å¯¼å…¥çš„Epicã€Storyå’ŒTaskæ•°é‡
        """
        # é»˜è®¤YAMLè·¯å¾„
        if not yaml_path:
            yaml_path = os.path.join(self.ai_dir, "roadmap", "current.yaml")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(yaml_path):
            logger.error(f"YAMLæ–‡ä»¶ä¸å­˜åœ¨: {yaml_path}")
            return 0, 0, 0

        # è¯»å–YAMLæ–‡ä»¶
        with open(yaml_path, "r", encoding="utf-8") as f:
            roadmap_data = yaml.safe_load(f)

        # å¯¼å…¥æ•°æ®
        result = self.db.import_from_yaml(roadmap_data)

        logger.info(f"ä»YAMLå¯¼å…¥æ•°æ®å®Œæˆ: {result[0]}ä¸ªEpic, {result[1]}ä¸ªStory, {result[2]}ä¸ªTask")
        return result

    def sync_task_from_filesystem(self, task_dir: str) -> Optional[str]:
        """
        ä»æ–‡ä»¶ç³»ç»ŸåŒæ­¥ä»»åŠ¡åˆ°æ•°æ®åº“

        Args:
            task_dir: ä»»åŠ¡ç›®å½•

        Returns:
            ä»»åŠ¡IDï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        # æ„å»ºä»»åŠ¡æ–‡ä»¶è·¯å¾„
        task_file = os.path.join(task_dir, "task.md")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(task_file):
            logger.error(f"ä»»åŠ¡æ–‡ä»¶ä¸å­˜åœ¨: {task_file}")
            return None

        # è¯»å–ä»»åŠ¡æ–‡ä»¶
        with open(task_file, "r", encoding="utf-8") as f:
            content = f.read()

        # è§£æYAMLå‰è¨€
        try:
            # æŸ¥æ‰¾YAMLå‰è¨€
            if content.startswith("---"):
                end_index = content.find("---", 3)
                if end_index > 0:
                    yaml_content = content[3:end_index].strip()
                    metadata = yaml.safe_load(yaml_content)

                    # æå–æè¿°
                    description = ""
                    header_index = content.find("# ", end_index)
                    if header_index > 0:
                        description_index = content.find("## ä»»åŠ¡æè¿°", header_index)
                        if description_index > 0:
                            next_section = content.find("##", description_index + 12)
                            if next_section > 0:
                                description = content[description_index + 12 : next_section].strip()
                            else:
                                description = content[description_index + 12 :].strip()

                    # å‡†å¤‡ä»»åŠ¡æ•°æ®
                    task_data = {
                        "id": metadata.get("id", ""),
                        "title": metadata.get("title", ""),
                        "description": description,
                        "story_id": metadata.get("story_id", ""),
                        "status": metadata.get("status", "todo"),
                        "priority": metadata.get("priority", "P2"),
                        "estimate": metadata.get("estimate", 8),
                        "assignee": metadata.get("assignee", ""),
                    }

                    # æå–æ ‡ç­¾
                    labels = metadata.get("tags", [])

                    # åˆ›å»ºæˆ–æ›´æ–°ä»»åŠ¡
                    if self.db.get_task(task_data["id"]):
                        self.db.update_task(task_data["id"], task_data, labels)
                    else:
                        self.db.create_task(task_data, labels)

                    logger.info(f"ä»æ–‡ä»¶ç³»ç»ŸåŒæ­¥ä»»åŠ¡å®Œæˆ: {task_data['id']}")
                    return task_data["id"]
        except Exception as e:
            logger.error(f"è§£æä»»åŠ¡æ–‡ä»¶å¤±è´¥: {e}")

        return None

    def sync_story_from_filesystem(self, story_file: str) -> Optional[str]:
        """
        ä»æ–‡ä»¶ç³»ç»ŸåŒæ­¥æ•…äº‹åˆ°æ•°æ®åº“

        Args:
            story_file: æ•…äº‹æ–‡ä»¶è·¯å¾„

        Returns:
            æ•…äº‹IDï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(story_file):
            logger.error(f"æ•…äº‹æ–‡ä»¶ä¸å­˜åœ¨: {story_file}")
            return None

        # è¯»å–æ•…äº‹æ–‡ä»¶
        with open(story_file, "r", encoding="utf-8") as f:
            content = f.read()

        # è§£æYAMLå‰è¨€
        try:
            # æŸ¥æ‰¾YAMLå‰è¨€
            if content.startswith("---"):
                end_index = content.find("---", 3)
                if end_index > 0:
                    yaml_content = content[3:end_index].strip()
                    metadata = yaml.safe_load(yaml_content)

                    # æå–æè¿°
                    description = ""
                    header_index = content.find("# ", end_index)
                    if header_index > 0:
                        description_index = content.find("## æ¦‚è¿°", header_index)
                        if description_index > 0:
                            next_section = content.find("##", description_index + 8)
                            if next_section > 0:
                                description = content[description_index + 8 : next_section].strip()
                            else:
                                description = content[description_index + 8 :].strip()

                    # å‡†å¤‡æ•…äº‹æ•°æ®
                    story_data = {
                        "id": metadata.get("id", "").strip('"'),
                        "title": metadata.get("title", "").strip('"'),
                        "description": description,
                        "status": metadata.get("status", "planned").strip('"'),
                        "progress": metadata.get("progress", 0),
                        "epic_id": metadata.get("epic", "").strip('"'),
                        "created_at": metadata.get("created_at", datetime.now().isoformat()).strip(
                            '"'
                        ),
                        "updated_at": metadata.get("updated_at", datetime.now().isoformat()).strip(
                            '"'
                        ),
                    }

                    # åˆ›å»ºæˆ–æ›´æ–°æ•…äº‹
                    if self.db.get_story(story_data["id"]):
                        self.db.update_story(story_data["id"], story_data)
                    else:
                        self.db.create_story(story_data)

                    logger.info(f"ä»æ–‡ä»¶ç³»ç»ŸåŒæ­¥æ•…äº‹å®Œæˆ: {story_data['id']}")
                    return story_data["id"]
        except Exception as e:
            logger.error(f"è§£ææ•…äº‹æ–‡ä»¶å¤±è´¥: {e}")

        return None

    def sync_all_from_filesystem(self) -> Tuple[int, int]:
        """
        ä»æ–‡ä»¶ç³»ç»ŸåŒæ­¥æ‰€æœ‰æ•°æ®åˆ°æ•°æ®åº“

        Returns:
            åŒæ­¥çš„æ•…äº‹å’Œä»»åŠ¡æ•°é‡
        """
        # åŒæ­¥æ•…äº‹
        stories_dir = os.path.join(self.ai_dir, "stories")
        story_count = 0
        if os.path.exists(stories_dir):
            for file_name in os.listdir(stories_dir):
                if file_name.endswith(".md"):
                    story_file = os.path.join(stories_dir, file_name)
                    if self.sync_story_from_filesystem(story_file):
                        story_count += 1

        # åŒæ­¥ä»»åŠ¡
        tasks_dir = os.path.join(self.ai_dir, "tasks")
        task_count = 0
        if os.path.exists(tasks_dir):
            for dir_name in os.listdir(tasks_dir):
                task_dir = os.path.join(tasks_dir, dir_name)
                if os.path.isdir(task_dir):
                    if self.sync_task_from_filesystem(task_dir):
                        task_count += 1

        logger.info(f"ä»æ–‡ä»¶ç³»ç»ŸåŒæ­¥æ•°æ®å®Œæˆ: {story_count}ä¸ªæ•…äº‹, {task_count}ä¸ªä»»åŠ¡")
        return story_count, task_count

    # ===== GitHubåŒæ­¥ =====

    def sync_to_github(self) -> Dict[str, Any]:
        """
        åŒæ­¥æ•°æ®åˆ°GitHub

        è°ƒç”¨ç°æœ‰çš„GitHubåŒæ­¥è„šæœ¬ã€‚
        è¿™é‡Œä»…ä½œä¸ºæ¥å£ï¼Œå®é™…å®ç°éœ€è¦é›†æˆç°æœ‰GitHubå¤„ç†é€»è¾‘ã€‚

        Returns:
            åŒæ­¥ç»“æœ
        """
        # å…ˆåŒæ­¥åˆ°YAML
        yaml_path = self.sync_to_roadmap_yaml()

        # TODO: è°ƒç”¨GitHubåŒæ­¥é€»è¾‘
        # è¿™é‡Œéœ€è¦é›†æˆç°æœ‰çš„GitHubåŒæ­¥è„šæœ¬

        result = {
            "success": True,
            "message": "æ•°æ®å·²åŒæ­¥åˆ°GitHub",
            "yaml_path": yaml_path,
            "created": 0,
            "updated": 0,
        }

        logger.info(f"æ•°æ®åŒæ­¥åˆ°GitHub: {result}")
        return result

    def sync_from_github(self) -> Dict[str, Any]:
        """
        ä»GitHubåŒæ­¥æ•°æ®

        è°ƒç”¨ç°æœ‰çš„GitHubåŒæ­¥è„šæœ¬ã€‚
        è¿™é‡Œä»…ä½œä¸ºæ¥å£ï¼Œå®é™…å®ç°éœ€è¦é›†æˆç°æœ‰GitHubå¤„ç†é€»è¾‘ã€‚

        Returns:
            åŒæ­¥ç»“æœ
        """
        # TODO: è°ƒç”¨GitHubåŒæ­¥é€»è¾‘
        # è¿™é‡Œéœ€è¦é›†æˆç°æœ‰çš„GitHubåŒæ­¥è„šæœ¬

        # åŒæ­¥å®Œæˆåï¼Œä»YAMLå¯¼å…¥æ•°æ®åº“
        yaml_path = os.path.join(self.ai_dir, "roadmap", "current.yaml")
        epic_count, story_count, task_count = self.sync_from_roadmap_yaml(yaml_path)

        result = {
            "success": True,
            "message": "ä»GitHubåŒæ­¥æ•°æ®å®Œæˆ",
            "yaml_path": yaml_path,
            "epics": epic_count,
            "stories": story_count,
            "tasks": task_count,
        }

        logger.info(f"ä»GitHubåŒæ­¥æ•°æ®: {result}")
        return result
