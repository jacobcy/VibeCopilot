#!/usr/bin/env python3
"""
GitDiagram é¡¹ç›®åˆ†æå·¥å…·

æ­¤è„šæœ¬ç”¨äºåˆ†æé¡¹ç›®ç»“æ„å¹¶ç”Ÿæˆæ¶æ„å›¾ï¼Œå¸®åŠ©å¼€å‘è€…ç†è§£é¡¹ç›®æ¡†æ¶ã€
åˆ¶å®šè·¯çº¿å›¾æˆ–åœ¨ä»£ç é‡æ„åæ›´æ–°é¡¹ç›®æ–‡æ¡£ã€‚

ä½¿ç”¨æ–¹æ³•:
  python analyze.py --path /path/to/project [--output /path/to/output] [--instructions "è‡ªå®šä¹‰æŒ‡ä»¤"]

å‚æ•°:
  --path: è¦åˆ†æçš„é¡¹ç›®è·¯å¾„ï¼ˆå¿…å¡«ï¼‰
  --output: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•
  --instructions: è‡ªå®šä¹‰åˆ†ææŒ‡ä»¤ï¼Œå¦‚"çªå‡ºæ˜¾ç¤ºæ•°æ®æµ"
  --openai-key: OpenAI APIå¯†é’¥(å¯é€‰)
"""

import argparse
import base64
import json
import os
import re
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import requests
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å…¨å±€å˜é‡
DEFAULT_OUTPUT_DIR = Path.cwd()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
GITHUB_PAT = os.getenv("GITHUB_PAT", "")
AI_MODEL = os.getenv("AI_MODEL", "gpt-4o-mini")  # é»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­æŒ‡å®šçš„æ¨¡å‹


class GitAnalyzer:
    """Gité¡¹ç›®åˆ†æå™¨ç±»"""

    def __init__(
        self,
        project_path: str,
        output_path: str = None,
        custom_instructions: str = "",
        openai_key: str = None,
    ):
        self.project_path = Path(project_path).resolve()
        self.output_path = Path(output_path or DEFAULT_OUTPUT_DIR).resolve()
        self.custom_instructions = custom_instructions
        self.openai_key = openai_key or OPENAI_API_KEY

        # éªŒè¯é¡¹ç›®è·¯å¾„
        if not self.project_path.exists():
            raise ValueError(f"é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: {self.project_path}")

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_path.mkdir(parents=True, exist_ok=True)

        # å‡†å¤‡ç»“æœæ–‡ä»¶
        self.diagram_file = self.output_path / "project_diagram.md"
        self.explanation_file = self.output_path / "project_explanation.md"

    def collect_file_paths(self) -> str:
        """æ”¶é›†é¡¹ç›®æ–‡ä»¶è·¯å¾„"""
        print("æ”¶é›†é¡¹ç›®æ–‡ä»¶è·¯å¾„...")

        exclude_patterns = [
            ".git/",
            "node_modules/",
            "venv/",
            "__pycache__/",
            ".vscode/",
            ".idea/",
            "dist/",
            "build/",
            ".DS_Store",
            "*.pyc",
            "*.pyo",
            "*.pyd",
            "*.so",
            "*.dll",
            "*.class",
            "*.exe",
            "*.bin",
            "*.jpg",
            "*.jpeg",
            "*.png",
            "*.gif",
            "*.ico",
            "*.svg",
            "*.ttf",
            "*.woff",
            "*.webp",
            "yarn.lock",
            "package-lock.json",
            "*.log",
        ]

        def should_include(path: Path) -> bool:
            """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«åŒ…å«"""
            path_str = str(path)
            return not any(pattern in path_str for pattern in exclude_patterns)

        paths = []
        for root, dirs, files in os.walk(self.project_path):
            # ä¿®æ”¹dirsåˆ—è¡¨ï¼Œç§»é™¤ä¸éœ€è¦éå†çš„ç›®å½•
            dirs[:] = [d for d in dirs if should_include(Path(root) / d)]

            for file in files:
                file_path = Path(root) / file
                if should_include(file_path):
                    # å­˜å‚¨ç›¸å¯¹è·¯å¾„
                    rel_path = file_path.relative_to(self.project_path)
                    paths.append(str(rel_path))

        return "\n".join(sorted(paths))

    def get_readme_content(self) -> str:
        """è·å–é¡¹ç›®READMEå†…å®¹"""
        print("è·å–é¡¹ç›®READMEå†…å®¹...")

        readme_candidates = ["README.md", "README", "Readme.md", "readme.md"]

        for candidate in readme_candidates:
            readme_path = self.project_path / candidate
            if readme_path.exists():
                return readme_path.read_text(encoding="utf-8")

        print("è­¦å‘Š: æœªæ‰¾åˆ°READMEæ–‡ä»¶")
        return "é¡¹ç›®æœªåŒ…å«READMEæ–‡ä»¶ã€‚"

    def analyze_project(self) -> Tuple[str, str]:
        """åˆ†æé¡¹ç›®ç»“æ„å¹¶ç”Ÿæˆæ¶æ„å›¾"""
        print("å¼€å§‹åˆ†æé¡¹ç›®ç»“æ„...")

        # æ”¶é›†é¡¹ç›®æ•°æ®
        file_tree = self.collect_file_paths()
        readme = self.get_readme_content()

        # å‡†å¤‡è¯·æ±‚æ•°æ®
        data = {"file_tree": file_tree, "readme": readme, "instructions": self.custom_instructions}

        explanation = ""
        component_mapping = ""
        diagram = ""

        try:
            # æ¨¡æ‹ŸGitDiagramçš„å¤„ç†æµç¨‹
            explanation = self._generate_explanation(data)
            component_mapping = self._generate_component_mapping(explanation, data)
            diagram = self._generate_diagram(explanation, component_mapping)
        except Exception as e:
            print(f"é”™è¯¯: åˆ†æè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
            sys.exit(1)

        return explanation, diagram

    def _generate_explanation(self, data: Dict) -> str:
        """ç”Ÿæˆé¡¹ç›®è§£é‡Š"""
        print("æ­£åœ¨ç”Ÿæˆé¡¹ç›®è§£é‡Š...")

        # ä½¿ç”¨OpenAI APIç”Ÿæˆ
        if not self.openai_key:
            print("é”™è¯¯: éœ€è¦æä¾›OpenAI APIå¯†é’¥")
            sys.exit(1)

        # æ„å»ºæç¤º
        system_prompt = """
        æ‚¨æ˜¯ä¸€ä½è½¯ä»¶æ¶æ„ä¸“å®¶ï¼Œè¯·åˆ†ææä¾›çš„é¡¹ç›®æ–‡ä»¶ç»“æ„å’ŒREADMEï¼Œè¯¦ç»†è§£é‡Šè¯¥é¡¹ç›®çš„æ¶æ„å’Œè®¾è®¡ã€‚
        æ‚¨çš„åˆ†æåº”åŒ…æ‹¬ï¼š
        1. é¡¹ç›®çš„ç±»å‹å’Œç›®çš„
        2. ä¸»è¦ç»„ä»¶å’Œå®ƒä»¬çš„åŠŸèƒ½
        3. ç»„ä»¶ä¹‹é—´çš„å…³ç³»å’Œæ•°æ®æµ
        4. ä½¿ç”¨çš„æŠ€æœ¯æ ˆå’Œæ¡†æ¶
        5. æ¶æ„æ¨¡å¼å’Œè®¾è®¡åŸåˆ™
        6. é¡¹ç›®çš„å±‚æ¬¡ç»“æ„

        è¯·æä¾›è¯¦ç»†çš„è§£é‡Šï¼Œä»¥ä¾¿åç»­å¯ä»¥ç”Ÿæˆå‡†ç¡®çš„æ¶æ„å›¾ã€‚
        """

        user_prompt = f"""
        è¯·åˆ†æä»¥ä¸‹é¡¹ç›®:

        <file_tree>
        {data['file_tree']}
        </file_tree>

        <readme>
        {data['readme']}
        </readme>

        {f"<instructions>{data['instructions']}</instructions>" if data['instructions'] else ""}
        """

        try:
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.openai_key}",
                },
                json={
                    "model": AI_MODEL,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    "temperature": 0.1,
                },
            )
            response.raise_for_status()
            explanation = (
                response.json().get("choices", [{}])[0].get("message", {}).get("content", "")
            )
            return explanation
        except Exception as e:
            print(f"é”™è¯¯: è°ƒç”¨OpenAI APIå¤±è´¥: {e}")
            sys.exit(1)

    def _generate_component_mapping(self, explanation: str, data: Dict) -> str:
        """ç”Ÿæˆç»„ä»¶æ˜ å°„"""
        print("æ­£åœ¨ç”Ÿæˆç»„ä»¶æ˜ å°„...")

        # ä½¿ç”¨OpenAI APIç”Ÿæˆ
        if not self.openai_key:
            print("é”™è¯¯: éœ€è¦æä¾›OpenAI APIå¯†é’¥")
            sys.exit(1)

        system_prompt = """
        æ‚¨æ˜¯ä¸€ä½è½¯ä»¶æ¶æ„ä¸“å®¶ï¼Œè¯·å°†ç³»ç»Ÿæ¶æ„ä¸­çš„ç»„ä»¶æ˜ å°„åˆ°å…·ä½“çš„æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„ã€‚
        åˆ†æä¸Šä¸‹æ–‡ä¸­çš„ç³»ç»Ÿè§£é‡Šï¼Œæ‰¾å‡ºå…³é”®ç»„ä»¶ï¼Œç„¶åå°†æ¯ä¸ªç»„ä»¶å¯¹åº”åˆ°æ–‡ä»¶æ ‘ä¸­çš„å…·ä½“è·¯å¾„ã€‚

        è¾“å‡ºæ ¼å¼å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ï¼š
        <component_mapping>
        1. [ç»„ä»¶åç§°]: [æ–‡ä»¶/ç›®å½•è·¯å¾„]
        2. [ç»„ä»¶åç§°]: [æ–‡ä»¶/ç›®å½•è·¯å¾„]
        ...
        </component_mapping>
        """

        user_prompt = f"""
        è¯·åˆ†æä»¥ä¸‹ç³»ç»Ÿè§£é‡Šï¼Œå¹¶å°†ç»„ä»¶æ˜ å°„åˆ°å¯¹åº”çš„æ–‡ä»¶æˆ–ç›®å½•ï¼š

        <explanation>
        {explanation}
        </explanation>

        <file_tree>
        {data['file_tree']}
        </file_tree>
        """

        try:
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.openai_key}",
                },
                json={
                    "model": AI_MODEL,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    "temperature": 0.1,
                },
            )
            response.raise_for_status()
            mapping = response.json().get("choices", [{}])[0].get("message", {}).get("content", "")

            # æå–<component_mapping>æ ‡ç­¾ä¸­çš„å†…å®¹
            match = re.search(r"<component_mapping>(.*?)</component_mapping>", mapping, re.DOTALL)
            if match:
                return match.group(1).strip()
            return mapping
        except Exception as e:
            print(f"é”™è¯¯: è°ƒç”¨OpenAI APIå¤±è´¥: {e}")
            sys.exit(1)

    def _generate_diagram(self, explanation: str, component_mapping: str) -> str:
        """ç”Ÿæˆæ¶æ„å›¾"""
        print("æ­£åœ¨ç”Ÿæˆæ¶æ„å›¾...")

        # ä½¿ç”¨OpenAI APIç”Ÿæˆ
        if not self.openai_key:
            print("é”™è¯¯: éœ€è¦æä¾›OpenAI APIå¯†é’¥")
            sys.exit(1)

        system_prompt = """
        æ‚¨æ˜¯ä¸€ä½è½¯ä»¶æ¶æ„ä¸“å®¶ï¼Œè¯·æ ¹æ®ç³»ç»Ÿè§£é‡Šå’Œç»„ä»¶æ˜ å°„ç”ŸæˆMermaidæ ¼å¼çš„æ¶æ„å›¾ã€‚

        éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
        1. ä½¿ç”¨flowchart TDç”Ÿæˆè‡ªä¸Šè€Œä¸‹çš„æµç¨‹å›¾
        2. ä¸ºä¸åŒç±»å‹çš„ç»„ä»¶ä½¿ç”¨é€‚å½“çš„å½¢çŠ¶å’Œæ ·å¼
        3. ç¡®ä¿èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»æ¸…æ™°
        4. ä½¿ç”¨å­å›¾(subgraph)å¯¹ç›¸å…³ç»„ä»¶è¿›è¡Œåˆ†ç»„
        5. æ·»åŠ é¢œè‰²æ ·å¼å¢å¼ºå¯è¯»æ€§
        6. ä¸ºæ˜ å°„çš„ç»„ä»¶æ·»åŠ ç‚¹å‡»äº‹ä»¶ï¼Œæ ¼å¼ä¸º: click ComponentName "path/to/file"
        7. å›¾è¡¨åº”å‚ç›´æ’åˆ—ï¼Œé¿å…è¿‡é•¿çš„æ°´å¹³åˆ—è¡¨

        è¾“å‡ºå¿…é¡»æ˜¯æœ‰æ•ˆçš„Mermaid.jsä»£ç ï¼Œä¸è¦åŠ ä»»ä½•é¢å¤–è¯´æ˜ã€‚
        """

        user_prompt = f"""
        è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆæ¶æ„å›¾ï¼š

        <explanation>
        {explanation}
        </explanation>

        <component_mapping>
        {component_mapping}
        </component_mapping>
        """

        try:
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.openai_key}",
                },
                json={
                    "model": AI_MODEL,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    "temperature": 0.1,
                },
            )
            response.raise_for_status()
            diagram = response.json().get("choices", [{}])[0].get("message", {}).get("content", "")

            # æ¸…ç†è¾“å‡ºï¼Œç§»é™¤å¯èƒ½çš„```mermaidå’Œ```æ ‡è®°
            diagram = re.sub(r"^```mermaid\s*\n", "", diagram)
            diagram = re.sub(r"\n```$", "", diagram)

            return diagram
        except Exception as e:
            print(f"é”™è¯¯: è°ƒç”¨OpenAI APIå¤±è´¥: {e}")
            sys.exit(1)

    def save_results(self, explanation: str, diagram: str) -> None:
        """ä¿å­˜åˆ†æç»“æœ"""
        print("æ­£åœ¨ä¿å­˜åˆ†æç»“æœ...")

        # ä¿å­˜è§£é‡Šæ–‡ä»¶
        with open(self.explanation_file, "w", encoding="utf-8") as f:
            f.write("# é¡¹ç›®æ¶æ„è§£é‡Š\n\n")
            f.write(explanation)

        # ä¿å­˜å›¾è¡¨æ–‡ä»¶
        with open(self.diagram_file, "w", encoding="utf-8") as f:
            f.write("# é¡¹ç›®æ¶æ„å›¾\n\n")
            f.write("```mermaid\n")
            f.write(diagram)
            f.write("\n```\n")

        print(f"âœ… è§£é‡Šæ–‡ä»¶å·²ä¿å­˜è‡³: {self.explanation_file}")
        print(f"âœ… æ¶æ„å›¾å·²ä¿å­˜è‡³: {self.diagram_file}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="GitDiagramé¡¹ç›®åˆ†æå·¥å…·")
    parser.add_argument("--path", required=True, help="è¦åˆ†æçš„é¡¹ç›®è·¯å¾„")
    parser.add_argument("--output", help="è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•")
    parser.add_argument("--instructions", help="è‡ªå®šä¹‰åˆ†ææŒ‡ä»¤ï¼Œä¾‹å¦‚'çªå‡ºæ˜¾ç¤ºæ•°æ®æµ'")
    parser.add_argument("--openai-key", help="OpenAI APIå¯†é’¥")

    args = parser.parse_args()

    try:
        analyzer = GitAnalyzer(
            project_path=args.path,
            output_path=args.output,
            custom_instructions=args.instructions or "",
            openai_key=args.openai_key,
        )

        explanation, diagram = analyzer.analyze_project()
        analyzer.save_results(explanation, diagram)

        print("\nğŸ‰ é¡¹ç›®åˆ†æå®Œæˆï¼")
        print("æ‚¨å¯ä»¥åœ¨è¾“å‡ºç›®å½•ä¸­æŸ¥çœ‹è§£é‡Šæ–‡ä»¶å’Œæ¶æ„å›¾ã€‚")

    except Exception as e:
        print(f"é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
