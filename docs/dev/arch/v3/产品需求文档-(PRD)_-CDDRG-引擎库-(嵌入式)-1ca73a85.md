**产品需求文档 (PRD): CDDRG 引擎库 (嵌入式) - v1.0 (最终草案)**

**版本:** 1.0
**日期:** 2023年10月27日
**作者:** [你的名字/团队] & AI 助手

**1. 概述 (Overview)**

**1.1 背景:**
静态规则库难以维护且适应性差，而直接应用 LLM 进行自动化任务则易陷入失控的“Vibe Coding”和“幻觉”风险。为实现 **受控的、负责任的 AI 驱动自动化**，我们提出“命令驱动的动态规则生成”（CDDRG）范式，并遵循 **“文档 -> 规则 -> 代码”** 的核心工作流。此范式强调人类在目标设定（文档）、流程方法设计（规则）及关键决策（计划确认）中的核心作用，并通过 **知识循环** 实现持续改进。

**1.2 目标产品:**
本产品是一个名为 **`cddrg_engine`** 的 **Python 库 (Package)**。它作为 CDDRG 范式的核心技术支撑，封装了根据输入命令和上下文，动态生成**行动指南/执行计划**的逻辑。Agent 应用程序通过简单的函数调用嵌入此库，使其能够在人类的监督和确认下，基于丰富的知识源（包含规则、背景知识和历史日志）执行任务。

**1.3 核心架构:**
`cddrg_engine` 设计为嵌入式库，在 Agent 应用进程内运行。它直接访问本地文件系统的知识源、配置文件、本地向量数据库（ChromaDB）和元数据存储（SQLite），并通过网络与外部 LLM API 通信。此架构旨在简化集成、优化本地性能，并支持明确的 **人机交互模式**（指令 -> 查询规划 -> 人类确认 -> 执行报告 -> 知识存储）。

**1.4 解决的问题:**

* 为 Agent 提供按需、上下文感知且符合既定规则和背景知识的行动计划生成能力。
* 支持“文档 -> 规则 -> 代码”开发流程，强化人类在规则设计和计划审核阶段的控制力。
* 通过知识循环机制，使 Agent 能利用历史经验持续改进。
* 提供一个易于集成、本地优先的解决方案，降低 AI 自动化应用的开发门槛和运行风险。

**2. 目标与目的 (Goals and Objectives)**

* **主要目标:** 提供稳定、可靠、易用的 `cddrg_engine` Python 库，实现 CDDRG 范式下行动计划的动态生成。
* **次要目标:**
  * 支持从多样化本地知识源（规则、文档、日志）中进行有效检索。
  * 生成结构化、清晰的行动计划，便于人类审核和 Agent 执行。
  * 提供灵活的配置选项（模型、路径、模板等）。
  * 实现高效的本地知识索引（支持增量更新）。
  * 提供全面的 API 文档和单元测试。
  * 确保日志记录充分，支持可追溯性和调试。
* **衡量指标:** (保持不变，参考上一版 PRD)

**3. 目标用户 (Target Audience)**

* **主要用户:** 使用 Python 开发 AI Agent、自动化脚本、或需要将 AI 能力整合进现有工作流的开发者。
* **次要用户:** 负责设计和维护规则、知识库，并希望通过 AI 提升流程效率和可靠性的知识工程师、流程设计师。

**4. 范围 (Scope)**

**4.1 In-Scope (库提供的功能):**

* **配置加载与验证:** (同上一版)
* **知识索引管道:**
  * 扫描、处理（分块、向量化）并索引本地知识源文件（**支持区分规则、文档、日志等类型**）。
  * 存入本地向量库 (ChromaDB) 和元数据存储 (SQLite)。
  * **支持基于文件变化（修改时间/哈希）的增量索引**。
* **核心 API 函数:**
  * `initialize(config_path, force_reindex=False)`: 初始化，管理索引。
  * `generate_action_plan(command, parameters, context)`: **核心函数，生成结构化的行动计划**。
* **内部逻辑组件:**
  * 知识检索器: **能检索并区分规则、背景知识、历史日志等**。
  * Prompt 引擎: 使用模板组装包含多样化信息的 Prompt，**目标是生成行动计划**。
  * LLM 客户端: (同上一版)
  * 响应格式化器: **解析 LLM 响应，格式化为结构化的行动计划（如 JSON）**。
* **本地存储交互:** (同上一版)
* **日志记录:** (同上一版)

**4.2 Out-of-Scope (库不负责的功能):**

* **Agent 应用程序逻辑:** (同上一版)
* **用户界面 (UI/CLI) / 人机交互流程的具体实现:** 库只提供生成计划的函数，如何呈现给用户、获取确认由 Agent 负责。
* **知识源内容的创建与管理:** (同上一版)
* **行动计划的执行:** (同上一版)
* **知识循环中日志等信息的自动捕获与写入:** 库负责索引已有的知识源，Agent 或其他系统负责将新产生的日志等信息放入知识源目录。
* **规则冲突的自动解决:** (同上一版)
* **网络服务部署、复杂权限管理:** (同上一版)

**5. 用例 (Use Cases)**

* **UC-01: 初始化 CDDRG 引擎 (包含索引):** (基本同上一版，强调增量索引逻辑)
* **UC-02: Agent 请求行动计划 (核心流程):**
  * **Actor:** Agent 应用程序 (响应人类指令后，确认前)
  * **Preconditions:** `cddrg_engine` 已初始化。
  * **Flow:**
        1. Agent 收到人类指令，解析出 `command`, `parameters`, `context`。
        2. Agent 调用 `action_plan_json = cddrg_engine.generate_action_plan(command, parameters, context)`。
        3. 库执行内部流程：
            a.  **知识检索器:** 查询向量库和元数据，获取与命令和上下文相关的**规则、背景文档摘要、相关历史日志条目**等。
            b.  **Prompt 引擎:** 组装 Prompt，明确要求 LLM 基于提供的规则和背景知识，为执行该命令生成一个详细、安全的行动计划。
            c.  **LLM 客户端:** 与 LLM API 交互。
            d.  **响应格式化器:** 解析 LLM 响应，生成结构化的 `action_plan` (JSON)。
        4. 库返回 `action_plan_json` 给 Agent。
        5. **Agent 将此 `action_plan` 呈现给人类用户进行审核和确认。**
        6. (后续步骤由 Agent 完成) Agent 收到确认后，按照计划执行，记录日志。
* **UC-03: 更新知识源并重新索引:** (基本同上一版，强调触发增量索引)

**6. 功能需求 (Functional Requirements)**

* **FR-LIB-INIT-01 (`initialize`):** (同上一版，增加 `force_reindex` 参数)
* **FR-LIB-GEN-01 (`generate_action_plan`):**
  * **输入:** `command` (str), `parameters` (dict), `context` (dict)。
  * **核心功能:** 按序调用内部组件，最终目标是生成行动计划。
  * **输出:** 返回结构化的行动计划 (推荐 JSON 格式，Schema 需定义)。
  * (其他同上一版)
* **FR-IDX-01/02 (索引 - 文件处理):**
  * 必须能根据配置或文件元数据**区分知识源类型**（rule, doc, log等）。
  * 必须支持对不同类型文件采用不同的分块或预处理策略（可选）。
* **FR-IDX-03/04 (索引 - 向量化与存储):** (同上一版，元数据中需包含知识源类型)
* **FR-IDX-05 (索引 - 增量更新):** **必须**实现基于文件修改时间或内容哈希的增量索引机制，避免不必要的全量重建。
* **FR-CONF-01/02 (配置):** (同上一版，需增加配置项区分知识源类型及其处理方式，以及行动计划输出格式定义)
* **FR-RET-01 (知识检索):**
  * 必须能执行混合检索，结合向量相似度和元数据过滤（如按知识源类型、时间范围过滤日志）。
  * 必须能区分检索结果的来源类型，并可能根据类型调整其在 Prompt 中的优先级或展示方式。
* **FR-PROM-01 (Prompt 引擎):**
  * 模板必须能清晰地组织不同类型的输入（命令、上下文、规则约束、背景信息、历史参考）。
  * **Prompt 的核心目标必须是引导 LLM 生成一个结构化、可执行、包含检查点的行动计划**。
* **FR-LLM-01 (LLM 客户端):** (同上一版)
* **FR-RESP-01 (响应格式化):**
  * **核心要求: 必须能将 LLM 的（通常是自然语言或 Markdown 格式的）响应，稳定地解析并转换为预定义的结构化行动计划格式 (JSON Schema 需明确定义)**。
  * 需要具备一定的鲁棒性，能处理 LLM 输出格式的轻微偏差。
* **FR-LOG-01 (日志):** (同上一版，需确保记录了生成行动计划的关键输入和检索到的知识摘要)
* **FR-ERR-01 (错误处理):** (同上一版)

**7. 非功能需求 (Non-Functional Requirements)**

* (保持不变，参考上一版 PRD，特别强调性能、可靠性、API易用性、可维护性、安全性)

**8. 数据需求 (Data Requirements)**

* **配置文件:** (参考上一版，增加知识源类型定义、行动计划 Schema 定义或路径)
* **SQLite Schema (示例 - 增强):**
  * `knowledge_sources` (source_id TEXT PRIMARY KEY, file_path TEXT, source_type TEXT, last_modified REAL, content_hash TEXT, indexed_at TIMESTAMP)
  * `knowledge_chunks` (chunk_id TEXT PRIMARY KEY, source_id TEXT, chunk_text TEXT, vector_id TEXT, metadata_json TEXT) -- metadata 可存 chunk 类型等
  * `action_plan_log` (log_id INTEGER PRIMARY KEY AUTOINCREMENT, timestamp TIMESTAMP, command TEXT, context_json TEXT, generated_plan_json TEXT, raw_llm_response TEXT, retrieved_knowledge_ids_json TEXT) -- 用于审计和调试
* **Vector Store Schema:** (元数据需包含 `source_id`, `source_type`)
* **输出行动计划格式 (JSON Schema - 需详细定义，示例见上一版 PRD)**: 必须包含步骤列表，每个步骤应有描述、引用（规则/知识源 ID）、检查点等。

**9. 假设与依赖 (Assumptions and Dependencies)**

* (基本同上一版)
* **新增假设:** Agent 应用程序负责实现将行动计划呈现给用户并获取确认的交互逻辑。

**10. 未来的考虑/开放问题 (Future Considerations / Open Questions)**

* 如何设计健壮的“响应格式化器”以应对 LLM 输出的多样性？(使用 Pydantic 等库进行结构化输出约束？二次 LLM 调用进行格式化？)
* 如何优化知识检索策略以平衡规则的强制性与背景知识的参考性？
* 行动计划 Schema 如何设计才能兼顾通用性与特定任务的细节需求？
* 如何更自动化地将 Agent 执行日志纳入知识循环（格式标准化、自动归档）？
* 库是否需要提供校验行动计划有效性（如资源可用性）的辅助函数？
* 如何评估和持续改进 RGI 生成行动计划的质量和安全性？
